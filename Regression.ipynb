{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebe7d24",
   "metadata": {},
   "source": [
    "1. What is Simple Linear Regression?\n",
    "> A method to model the relationship between one independent and one dependent variable using a straight line.\n",
    "\n",
    "2. What are the key assumptions of Simple Linear Regression?**\n",
    "> Linearity, independence, homoscedasticity, and normality of residuals.\n",
    "\n",
    "3. What does the coefficient `m` represent in the equation Y = mX + c?**\n",
    "> The slope, representing how much Y changes with a unit change in X.\n",
    "\n",
    "4. What does the intercept `c` represent in the equation Y = mX + c?**\n",
    "> The value of Y when X is zero.\n",
    "\n",
    "5. How do we calculate the slope `m` in Simple Linear Regression?**\n",
    "> m = \\frac{n(\\sum XY) - (\\sum X)(\\sum Y)}{n(\\sum X^2) - (\\sum X)^2}\n",
    "\n",
    "6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
    "> To minimize the sum of the squared differences between observed and predicted values.\n",
    "\n",
    "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
    "> It indicates the proportion of variance in the dependent variable explained by the model.\n",
    "\n",
    "8. What is Multiple Linear Regression?**\n",
    "> A regression model with two or more independent variables predicting a dependent variable.\n",
    "\n",
    "9. What is the main difference between Simple and Multiple Linear Regression?**\n",
    "> Simple uses one independent variable; multiple uses two or more.\n",
    "\n",
    "10. What are the key assumptions of Multiple Linear Regression?**\n",
    "> Linearity, independence, homoscedasticity, normality, and no multicollinearity.\n",
    "\n",
    "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
    "> It refers to non-constant variance in errors, leading to inefficient and biased estimates.\n",
    "\n",
    "12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
    "> By removing correlated variables, using PCA, or applying regularization like Ridge or Lasso.\n",
    "\n",
    "13. What are some common techniques for transforming categorical variables for use in regression models?**\n",
    "> One-hot encoding, label encoding, and ordinal encoding.\n",
    "\n",
    "14. What is the role of interaction terms in Multiple Linear Regression?**\n",
    "> They capture the combined effect of two or more variables on the dependent variable.\n",
    "\n",
    "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
    "> In multiple regression, the intercept is the expected value of Y when all predictors are zero, which may not be meaningful.\n",
    "\n",
    "16. What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
    "> It shows the expected change in Y for a one-unit change in a predictor; it directly affects predicted outcomes.\n",
    "\n",
    "17. How does the intercept in a regression model provide context for the relationship between variables?**\n",
    "> It gives the baseline value of the dependent variable when all predictors are zero.\n",
    "\n",
    "18. What are the limitations of using R² as a sole measure of model performance?**\n",
    "> It doesn't account for model complexity, overfitting, or whether predictors are significant.\n",
    "\n",
    "19. How would you interpret a large standard error for a regression coefficient?**\n",
    "> It suggests the coefficient is not estimated precisely and may not be statistically significant.\n",
    "\n",
    "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
    "> It appears as a funnel shape; it must be corrected to ensure valid inference and prediction.\n",
    "\n",
    "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
    "> The model may be overfitting by including irrelevant predictors.\n",
    "\n",
    "22. Why is it important to scale variables in Multiple Linear Regression?**\n",
    "> To ensure that all variables contribute equally, especially when regularization is used.\n",
    "\n",
    "23. What is polynomial regression?**\n",
    "> A type of regression where the relationship between variables is modeled as an nth-degree polynomial.\n",
    "\n",
    "24. How does polynomial regression differ from linear regression?**\n",
    "> It models non-linear relationships by including higher-degree terms of the independent variable.\n",
    "\n",
    "25. When is polynomial regression used?**\n",
    "> When the data shows a non-linear trend that linear regression can't capture.\n",
    "\n",
    "26. What is the general equation for polynomial regression?**\n",
    ">\n",
    "Y = b_0 + b_1X + b_2X^2 + \\dots + b_nX^n\n",
    "\n",
    "\n",
    "27. Can polynomial regression be applied to multiple variables?**\n",
    "> Yes, using polynomial terms for each variable and their interactions.\n",
    "\n",
    "28. What are the limitations of polynomial regression?**\n",
    "> Prone to overfitting, sensitive to outliers, and can become complex quickly.\n",
    "\n",
    "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
    "> Cross-validation, adjusted R², AIC, BIC, and residual analysis.\n",
    "\n",
    "30. Why is visualization important in polynomial regression?**\n",
    "> To understand the model's fit and ensure it captures the data trend without overfitting.\n",
    "\n",
    "31. How is polynomial regression implemented in Python?**\n",
    "> Using `PolynomialFeatures` from `sklearn.preprocessing` and `LinearRegression` from `sklearn.linear_model`.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
